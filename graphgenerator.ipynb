{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Started server process [21744]\n",
      "INFO:     Waiting for application startup.\n",
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:50460 - \"GET /generate-graph?complexity=1&n_max=30 HTTP/1.1\" 200 OK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-232' coro=<Server.serve() done, defined at d:\\ML from Udemy\\venv\\Lib\\site-packages\\uvicorn\\server.py:68> exception=KeyboardInterrupt()>\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\ML from Udemy\\venv\\Lib\\site-packages\\uvicorn\\main.py\", line 579, in run\n",
      "    server.run()\n",
      "  File \"d:\\ML from Udemy\\venv\\Lib\\site-packages\\uvicorn\\server.py\", line 66, in run\n",
      "    return asyncio.run(self.serve(sockets=sockets))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\ML from Udemy\\venv\\Lib\\site-packages\\nest_asyncio.py\", line 30, in run\n",
      "    return loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\ML from Udemy\\venv\\Lib\\site-packages\\nest_asyncio.py\", line 92, in run_until_complete\n",
      "    self._run_once()\n",
      "  File \"d:\\ML from Udemy\\venv\\Lib\\site-packages\\nest_asyncio.py\", line 133, in _run_once\n",
      "    handle._run()\n",
      "  File \"d:\\ML from Udemy\\venv\\Lib\\asyncio\\events.py\", line 84, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"d:\\ML from Udemy\\venv\\Lib\\asyncio\\tasks.py\", line 386, in __wakeup\n",
      "    self.__step()\n",
      "  File \"d:\\ML from Udemy\\venv\\Lib\\asyncio\\tasks.py\", line 293, in __step\n",
      "    self.__step_run_and_handle_result(exc)\n",
      "  File \"d:\\ML from Udemy\\venv\\Lib\\asyncio\\tasks.py\", line 304, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"d:\\ML from Udemy\\venv\\Lib\\site-packages\\uvicorn\\server.py\", line 69, in serve\n",
      "    with self.capture_signals():\n",
      "  File \"d:\\ML from Udemy\\venv\\Lib\\contextlib.py\", line 144, in __exit__\n",
      "    next(self.gen)\n",
      "  File \"d:\\ML from Udemy\\venv\\Lib\\site-packages\\uvicorn\\server.py\", line 330, in capture_signals\n",
      "    signal.raise_signal(captured_signal)\n",
      "KeyboardInterrupt\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-252' coro=<Server.serve() done, defined at d:\\ML from Udemy\\venv\\Lib\\site-packages\\uvicorn\\server.py:68> exception=KeyboardInterrupt()>\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\ML from Udemy\\venv\\Lib\\site-packages\\uvicorn\\main.py\", line 579, in run\n",
      "    server.run()\n",
      "  File \"d:\\ML from Udemy\\venv\\Lib\\site-packages\\uvicorn\\server.py\", line 66, in run\n",
      "    return asyncio.run(self.serve(sockets=sockets))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\ML from Udemy\\venv\\Lib\\site-packages\\nest_asyncio.py\", line 30, in run\n",
      "    return loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\ML from Udemy\\venv\\Lib\\site-packages\\nest_asyncio.py\", line 92, in run_until_complete\n",
      "    self._run_once()\n",
      "  File \"d:\\ML from Udemy\\venv\\Lib\\site-packages\\nest_asyncio.py\", line 133, in _run_once\n",
      "    handle._run()\n",
      "  File \"d:\\ML from Udemy\\venv\\Lib\\asyncio\\events.py\", line 84, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"d:\\ML from Udemy\\venv\\Lib\\asyncio\\tasks.py\", line 386, in __wakeup\n",
      "    self.__step()\n",
      "  File \"d:\\ML from Udemy\\venv\\Lib\\asyncio\\tasks.py\", line 293, in __step\n",
      "    self.__step_run_and_handle_result(exc)\n",
      "  File \"d:\\ML from Udemy\\venv\\Lib\\asyncio\\tasks.py\", line 304, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"d:\\ML from Udemy\\venv\\Lib\\site-packages\\uvicorn\\server.py\", line 69, in serve\n",
      "    with self.capture_signals():\n",
      "  File \"d:\\ML from Udemy\\venv\\Lib\\contextlib.py\", line 144, in __exit__\n",
      "    next(self.gen)\n",
      "  File \"d:\\ML from Udemy\\venv\\Lib\\site-packages\\uvicorn\\server.py\", line 330, in capture_signals\n",
      "    signal.raise_signal(captured_signal)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:60157 - \"GET /generate-graph?complexity=1&n_max=30 HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:60560 - \"GET /generate-graph?complexity=1&n_max=30 HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:62448 - \"GET /generate-graph?complexity=O(1)&n_max=30 HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:60309 - \"GET /generate-graph?complexity=O(1)&n_max=30 HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:62038 - \"GET /generate-graph?complexity=O(1)&n_max=30 HTTP/1.1\" 200 OK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Shutting down\n",
      "INFO:     Waiting for application shutdown.\n",
      "INFO:     Application shutdown complete.\n",
      "INFO:     Finished server process [21744]\n"
     ]
    }
   ],
   "source": [
    "from fastapi import FastAPI, Query, HTTPException\n",
    "from fastapi.responses import FileResponse\n",
    "import nest_asyncio\n",
    "import uvicorn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "\n",
    "# Apply nest_asyncio to allow running Uvicorn in Jupyter/Colab\n",
    "nest_asyncio.apply()\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "def parse_and_generate_values(complexity_str, n):\n",
    "    # Clean up the input string\n",
    "    complexity_str = complexity_str.lower().replace(\" \", \"\")\n",
    "    \n",
    "    # Handle special cases\n",
    "    if complexity_str in [\"1\", \"c\", \"constant\", \"o(1)\",\"O(1)\"]:\n",
    "        return np.ones_like(n), \"O(1)\"\n",
    "        \n",
    "    elif complexity_str in [\"logn\", \"log(n)\", \"o(logn)\", \"o(log(n))\"]:\n",
    "        return np.log2(n), \"O(log n)\"\n",
    "        \n",
    "    elif complexity_str in [\"n\", \"linear\", \"o(n)\"]:\n",
    "        return n, \"O(n)\"\n",
    "        \n",
    "    elif complexity_str in [\"nlogn\", \"nlog(n)\", \"n*logn\", \"n*log(n)\", \"o(nlogn)\"]:\n",
    "        return n * np.log2(n), \"O(n log n)\"\n",
    "        \n",
    "    elif complexity_str in [\"n2\", \"n^2\", \"nsquared\", \"quadratic\", \"o(n2)\", \"o(n^2)\",\"n**2x\"]:\n",
    "        return n**2, \"O(n²)\"\n",
    "        \n",
    "    elif complexity_str in [\"n3\", \"n^3\", \"ncubed\", \"cubic\", \"o(n3)\", \"o(n^3)\",\"n**3\"]:\n",
    "        return n**3, \"O(n³)\"\n",
    "        \n",
    "    # Handle 2^h, 2^n, etc.\n",
    "    elif re.match(r\"2\\^[a-zA-Z]\", complexity_str) or complexity_str in [\"exponential\", \"o(2^n)\",\"2**n\",\"2**h\"]:\n",
    "        label = f\"O({complexity_str})\" if not complexity_str.startswith(\"o(\") else complexity_str.upper()\n",
    "        # Limit the values to avoid overflow\n",
    "        return np.where(n < 30, 2**n, np.inf), label\n",
    "        \n",
    "    elif complexity_str in [\"n!\", \"factorial\", \"o(n!)\"]:\n",
    "        # Use Stirling's approximation for large n to avoid overflow\n",
    "        return np.where(n < 20, np.array([np.math.factorial(int(i)) for i in n]), np.inf), \"O(n!)\"\n",
    "        \n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported complexity: {complexity_str}\")\n",
    "\n",
    "@app.get(\"/status\")\n",
    "def get_status():\n",
    "    return {\"message\": \"Server is running\"}\n",
    "\n",
    "@app.get(\"/generate-graph\")\n",
    "def generate_graph(\n",
    "    complexity: str = Query(..., description=\"Time complexity (e.g., 'nlogn', 'n2', '2^h')\"),\n",
    "    n_max: int = Query(100, description=\"Maximum input size to plot\")\n",
    "):\n",
    "    try:\n",
    "        # Ensure output directory exists\n",
    "        os.makedirs(\"output\", exist_ok=True)\n",
    "        \n",
    "        # Generate input sizes (more points for better curve)\n",
    "        n = np.linspace(1, n_max, 1000)\n",
    "        n[0] = 1  # Ensure we start at 1 to avoid log(0)\n",
    "        \n",
    "        # Generate complexity values and get the formatted label\n",
    "        values, label = parse_and_generate_values(complexity, n)\n",
    "        \n",
    "        # Create the plot\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(n, values, label=label, linewidth=2, color='blue')\n",
    "        \n",
    "        # Find appropriate scale based on data\n",
    "        if np.any(values > 1000):\n",
    "            plt.yscale('log')\n",
    "        \n",
    "        # Add labels and title\n",
    "        plt.xlabel('Input Size (n)')\n",
    "        plt.ylabel('Number of Operations')\n",
    "        plt.title(f'Time Complexity Analysis: {label}')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Add algorithm growth region\n",
    "        plt.fill_between(n, values, alpha=0.1, color='blue')\n",
    "        \n",
    "        # Save the plot\n",
    "        output_path = \"output/time_complexity_graph.png\"\n",
    "        plt.savefig(output_path, dpi=300)\n",
    "        plt.close()\n",
    "        \n",
    "        # Return the image file\n",
    "        return FileResponse(output_path, media_type=\"image/png\")\n",
    "    \n",
    "    except ValueError as e:\n",
    "        raise HTTPException(status_code=400, detail=str(e))\n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=500, detail=f\"Error generating graph: {str(e)}\")\n",
    "\n",
    "# Run the server\n",
    "if __name__ == \"__main__\":\n",
    "    uvicorn.run(app, host=\"0.0.0.0\", port=8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install fastapi uvicorn nest_asyncio"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
